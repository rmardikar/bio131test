{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partners: Radhika Mardikar, Xinxin Mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generated random files with different percentages of 0 and 1. Our jupyter has some issue with showing the files, but when checking the length of the files, we see that the length is what we want it to be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104857600"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifty = np.random.choice([0, 1], size=838860800, replace=True, p=[0.5, 0.5])\n",
    "fifty = np.packbits(fifty)\n",
    "sixty = np.random.choice([0, 1], size=838860800, replace=True, p=[0.6, 0.4])\n",
    "sixty = np.packbits(sixty)\n",
    "seventy = np.random.choice([0, 1], size=838860800, replace=True, p=[0.7, 0.3])\n",
    "seventy = np.packbits(seventy)\n",
    "eighty = np.random.choice([0, 1], size=838860800, replace=True, p=[0.8, 0.2])\n",
    "eighty = np.packbits(eighty)\n",
    "ninety = np.random.choice([0, 1], size=838860800, replace=True, p=[0.9, 0.1])\n",
    "ninety = np.packbits(ninety)\n",
    "full = np.random.choice([0, 1], size=838860800, replace=True, p=[1, 0])\n",
    "full = np.packbits(full)\n",
    "open(\"lab7/fifty\", \"wb\").write(fifty)\n",
    "open(\"lab7/sixty\", \"wb\").write(sixty)\n",
    "open(\"lab7/seventy\", \"wb\").write(seventy)\n",
    "open(\"lab7/eighty\", \"wb\").write(eighty)\n",
    "open(\"lab7/ninety\", \"wb\").write(ninety)\n",
    "open(\"lab7/full\", \"wb\").write(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once those files have been generated, we generate random sequences of DNA and protein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ratio = [1/20]*20\n",
    "seq = np.random.choice(['A', 'T', 'C', 'G'], size=100000000, replace=True, p=[0.25, 0.25, 0.25, 0.25])\n",
    "open(\"lab7/nt_seq.fa\", \"w\").write(\"\".join(seq))\n",
    "protseq = np.random.choice(['A', 'C', 'D', 'E', 'F', 'G', 'H','I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S','T', 'V', 'W', 'Y'], \n",
    "                           size=100000000, replace=True, p= ratio)\n",
    "open(\"lab7/prot_seq.fa\", \"w\").write(\"\".join(protseq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the sequences (both DNA and protein) have been generated, we can start compressing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Into terminal, we typed in the following_\n",
    "\n",
    "```sh\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time gzip -k fifty\n",
    "\n",
    "real    0m3.502s\n",
    "user    0m3.413s\n",
    "sys     0m0.088s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time bzip2 -k fifty\n",
    "\n",
    "real    0m16.694s\n",
    "user    0m16.581s\n",
    "sys     0m0.113s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time ArithmeticCompress fifty fifty.art\n",
    "\n",
    "real    0m41.227s\n",
    "user    0m40.962s\n",
    "sys     0m0.229s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ rm fifty.bz2\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time pbzip2 -k fifty\n",
    "\n",
    "real    0m1.500s\n",
    "user    0m39.210s\n",
    "sys     0m0.943s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time gzip -k sixty\n",
    "\n",
    "real    0m4.258s\n",
    "user    0m4.145s\n",
    "sys     0m0.112s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time bzip2 -k sixty\n",
    "\n",
    "real    0m15.766s\n",
    "user    0m15.629s\n",
    "sys     0m0.136s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time ArithmeticCompress sixty sixty.art\n",
    "\n",
    "real    0m41.246s\n",
    "user    0m41.124s\n",
    "sys     0m0.120s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ rm sixty.bz2\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time pbzip2 -k sixty\n",
    "\n",
    "real    0m1.357s\n",
    "user    0m35.473s\n",
    "sys     0m0.825s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time gzip -k seventy\n",
    "\n",
    "real    0m6.221s\n",
    "user    0m6.048s\n",
    "sys     0m0.168s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time bzip2 -k seventy\n",
    "\n",
    "real    0m13.790s\n",
    "user    0m13.709s\n",
    "sys     0m0.081s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time ArithmeticCompress sixty seventy.art\n",
    "\n",
    "real    0m2.597s\n",
    "user    0m2.579s\n",
    "sys     0m0.017s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ rm seventy.bz2\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time pbzip2 -k seventy\n",
    "\n",
    "real    0m1.179s\n",
    "user    0m30.356s\n",
    "sys     0m0.773s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time gzip -k eighty\n",
    "\n",
    "real    0m13.435s\n",
    "user    0m13.259s\n",
    "sys     0m0.117s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time bzip2 -k eighty\n",
    "\n",
    "real    0m12.001s\n",
    "user    0m11.881s\n",
    "sys     0m0.121s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time ArithmeticCompress eighty eighty.art\n",
    "\n",
    "real    0m35.714s\n",
    "user    0m35.366s\n",
    "sys     0m0.325s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ rm eighty.bz2\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time pbzip2 -k eighty\n",
    "\n",
    "real    0m0.959s\n",
    "user    0m23.869s\n",
    "sys     0m0.817s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time gzip -k ninety\n",
    "\n",
    "real    0m19.363s\n",
    "user    0m19.192s\n",
    "sys     0m0.141s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time bzip2 -k ninety\n",
    "\n",
    "real    0m10.649s\n",
    "user    0m10.564s\n",
    "sys     0m0.084s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time ArithmeticCompress ninety ninety.art\n",
    "\n",
    "real    0m29.345s\n",
    "user    0m29.192s\n",
    "sys     0m0.152s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ rm ninety.bz2\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time pbzip2 -k ninety\n",
    "\n",
    "real    0m0.753s\n",
    "user    0m18.753s\n",
    "sys     0m0.607s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time gzip -k full\n",
    "\n",
    "real    0m0.725s\n",
    "user    0m0.657s\n",
    "sys     0m0.064s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time bzip2 -k full\n",
    "\n",
    "real    0m1.030s\n",
    "user    0m0.998s\n",
    "sys     0m0.032s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time ArithmeticCompress full full.art\n",
    "\n",
    "real    0m14.816s\n",
    "user    0m14.751s\n",
    "sys     0m0.065s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ rm full.bz2\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time pbzip2 -k full\n",
    "\n",
    "real    0m0.110s\n",
    "user    0m1.813s\n",
    "sys     0m0.112s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time gzip -k nt_seq.fa\n",
    "\n",
    "real    0m12.297s\n",
    "user    0m12.244s\n",
    "sys     0m0.053s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time bzip2 -k nt_seq.fa\n",
    "\n",
    "real    0m9.521s\n",
    "user    0m9.464s\n",
    "sys     0m0.057s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time ArithmeticCompress nt_seq.fa nt_seq.fa.art\n",
    "\n",
    "real    0m21.686s\n",
    "user    0m21.593s\n",
    "sys     0m0.093s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ rm nt_seq.fa.bz2\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time pbzip2 -k nt_seq.fa\n",
    "\n",
    "real    0m0.653s\n",
    "user    0m15.823s\n",
    "sys     0m0.530s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time gzip -k prot_seq.fa\n",
    "\n",
    "real    0m4.246s\n",
    "user    0m4.150s\n",
    "sys     0m0.096s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time bzip2 -k prot_seq.fa\n",
    "\n",
    "real    0m9.958s\n",
    "user    0m9.893s\n",
    "sys     0m0.065s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time ArithmeticCompress prot_seq.fa prot_seq.fa.art\n",
    "\n",
    "real    0m30.016s\n",
    "user    0m29.943s\n",
    "sys     0m0.073s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ rm prot_seq.fa.bz2\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time pbzip2 -k prot_seq.fa\n",
    "\n",
    "real    0m0.766s\n",
    "user    0m18.678s\n",
    "sys     0m0.705s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                    Time to Compress\n",
    "\n",
    "| File name | gzip(in s)| bzip2(in s)| pbzip2(in s)| Arithmetic compress(in s)|Input size(MB)|\n",
    "| --------- |:---------:| :---------:|:----------:|:-------:|--------:|\n",
    "| fifty     | 3.512     | 17.310     | 1.513      | 42.064| 105 MB|\n",
    "| sixty     | 4.279     | 16.075     | 1.375      | 41.306| 105 MB |\n",
    "| seventy   | 5.971     | 14.276     | 1.140      | 39.535| 105 MB | \n",
    "| eighty    | 13.490    | 12.111     | 0.935      | 35.460| 105 MB | \n",
    "| ninety    | 18.786    | 10.789     | 0.740      | 29.547| 105 MB | \n",
    "| full      | 0.715     | 1.02       | 0.096      | 14.838| 105 MB |\n",
    "| seq       | 12.156    | 9.581      | 0.664      | 21.903| 100 MB | \n",
    "| protseq   | 4.275     | 10.415     | 0.730      | 28.880| 100 MB |\n",
    "\n",
    "\n",
    "                                                  Output Size\n",
    "\n",
    "| File name | gzip(.gz) | bzip2(.bz2)| pbzip2(.bz2)| Arithmetic compress|Input size(MB)|\n",
    "| --------- |:---------:| :---------:|:----------: |:------------------------:|:----------: |\n",
    "| fifty     | 105 MB    |  105 MB    | 105 MB      | 105 MB  | 105 MB |\n",
    "| sixty     | 102 MB    | 105MB      | 105 MB      | 102 MB  | 105 MB |\n",
    "| seventy   | 93.6 MB   | 99.8 MB    | 99.8 MB     | 102 MB  | 105 MB |\n",
    "| eighty    | 81.2 MB   | 86.6 MB    | 86.7 MB     | 75.7 MB | 105 MB |\n",
    "| ninety    | 58.7 MB   | 61.2 MB    | 61.2 MB     | 49.2 MB | 105 MB |\n",
    "| full      | 102 KB    | 113 B      | 5.62 KB     | 1.03 KB | 105 MB |\n",
    "\n",
    "| File name | gzip(.gz) | bzip2(.bz2)| pbzip2(.bz2)| Arithmetic compress| Input size(MB)|\n",
    "| --------- |:---------:| :---------:|:----------: |:------------------------:|:----------: |\n",
    "| seq       | 29.2 MB   | 27.3 MB      | 27.3 MB     | 25 MB   | 100 MB |\n",
    "| protseq   | 60.6 MB   | 55.3 MB     | 55.3 MB     | 54 MB   | 100 MB |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer these in your iPython notebook.\n",
    "\n",
    "_1. Which algorithm achieves the best level of compression on each file type?_\n",
    "\n",
    "On the files with only 1s and 0s, arithmetic compression seemed to do best as the percentage of 0s increased. \n",
    "However as the percentage decreased, all of the compressions performed about the same.\n",
    "On the seq and protein seq files, arithmetic compress worked best.\n",
    "\n",
    "_2. Which algorithm is the fastest?_\n",
    "    \n",
    "In general, it seems that pbzip2 is the fastest algorithm.\n",
    "\n",
    "_3. What is the difference between bzip2 and pbzip2? Do you expect one to be faster and why?_\n",
    "    \n",
    "bzip2 is a compression method that uses the Burrows-Wheeler algorithm that only works on single files. pbzip2 is an implementation of bzip2 that supports multiple threads which improves speeds dramatically. For this reason, we expect pbzip2 to be faster and this is evidenced in the table above. \n",
    "\n",
    "_4. How does the level of compression change as the percentage of zeros increases? Why does this\n",
    "happen?_\n",
    "\n",
    "As the percentage of zeros increases, compression becomes better (able to be smaller). This happens because presumably fewer bits are required to encode the 0 and since 1s are much rarer, the extra bits required to encode those are overshadowed. \n",
    "\n",
    "_5. What is the minimum number of bits required to store a single DNA base?_\n",
    "\n",
    "The minimum number of bits to store a single DNA base is log2(4) which is 2 bits.\n",
    "    \n",
    "_6. What is the minimum number of bits required to store an amino acid letter?_\n",
    "\n",
    "The minimum number for an amino acid letter is log2(20) is about 4 bits.\n",
    "    \n",
    "_7. In your tests, how many bits did gzip and bzip2 actually require to store your random DNA and\n",
    "protein sequences?_\n",
    "\n",
    "Because the random DNA and protein sequences that we generated are at the uniform distribution, the ideal code should be 2 bits for DNA sequence and 4 bits for protein sequence. We have generated the 100000000 bases for each sequence. Thus, it requires 100000000 * 2 = 200000000 bits for DNA sequence, and 100000000 * 4 = 400000000 for protein sequence.\n",
    "\n",
    "_8. Are gzip and bzip2 performing well on DNA and proteins?_\n",
    "\n",
    "gzip and bzip2 performed comparably to the rest of the compression methods. They were neither significantly better nor worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for org in organismlist:\n",
    "    for enzyme in enzymelist:\n",
    "        \n",
    "        handle = Entrez.esearch(db=\"gene\",\n",
    "                                term = org + '[ORGN] AND ' + enzyme, \n",
    "                                idtype = 'acc', \n",
    "                                sort='relevance',\n",
    "                                retmax=1)\n",
    "        #print(org + '[ORGN]' + enzyme)\n",
    "        record = Entrez.read(handle)\n",
    "        idlist.append(record[\"IdList\"])\n",
    "        \n",
    "        handle2 = Entrez.esearch(db=\"nucleotide\",\n",
    "                                term = org + '[ORGN] AND ' + enzyme, \n",
    "                                idtype = 'acc', \n",
    "                                sort='relevance',\n",
    "                                retmax=1)\n",
    "        record2 = Entrez.read(handle2)\n",
    "        idlist2.append(record2[\"IdList\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"xinxinmo@berkeley.edu\"\n",
    "idlist = []\n",
    "#for i in range(1, 11):\n",
    "handle = Entrez.esearch(db=\"nucleotide\",\n",
    "                        term = \"gp120 \", \n",
    "                        idtype = 'acc', \n",
    "                        sort='relevance')\n",
    "#record = Entrez.read(handle)[\"IdList\"]\n",
    "#idlist.append(record[\"IdList\"])\n",
    "#for i in range(len(idlist)):\n",
    "allSeqs = \"\"\n",
    "ofile = open('lab7/multiFASTA', 'w')\n",
    "for i in Entrez.read(handle)['IdList']:\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id = i, rettype = 'fasta', retmode = 'text', retnum=1)\n",
    "    seqList = [line[:-1] for line in handle.readlines()[1:-1]]\n",
    "    seqString = ''.join(seqList)\n",
    "    ofile.write(seqString)\n",
    "    allSeqs = allSeqs + seqString\n",
    "    \n",
    "#print(seqString)\n",
    "ofile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_A priori, do you expect to achieve better or worse compression here than random data? Why?_\n",
    "\n",
    "We expect to achieve better compression than random data because adjacent nucleotides in a genome are not random â€“ everything has a place and purpose. \n",
    "\n",
    "We now compress the multiFASTA files using the different compression methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time gzip -k multiFASTA\n",
    "\n",
    "real    0m0.003s\n",
    "user    0m0.003s\n",
    "sys     0m0.001s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time bzip2 -k multiFASTA\n",
    "\n",
    "real    0m0.006s\n",
    "user    0m0.006s\n",
    "sys     0m0.001s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time ArithmeticCompress multiFASTA multiFASTA.art\n",
    "\n",
    "real    0m0.004s\n",
    "user    0m0.004s\n",
    "sys     0m0.000s\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ rm multiFASTA.bz2\n",
    "be131-03@meowth:~/lab7/bio131test/lab7$ time pbzip2 -k multiFASTA\n",
    "\n",
    "real    0m0.003s\n",
    "user    0m0.003s\n",
    "sys     0m0.000s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How does the compression ratio of this file compare to random data?_\n",
    "\n",
    "Compared to 70% zero, the compression ratio of this file is lower. This shows that genomic data is not randomized.\n",
    "\n",
    "\n",
    "The original multiFASTA file was 8.44 kB\n",
    "\n",
    "| File name | gzip(.gz) | bzip2(.bz2)| pbzip2(.bz2)| Arithmetic compress|\n",
    "| --------- |:---------:| :---------:|:----------: |-------------------:|\n",
    "| multiFASTA (time taken in s)| 0.003| 0.006 |0.003| 0.004| \n",
    "| multiFASTA (output size)| 1.88 kB| 1.91 kB| 1.91 kB| 3.04 kB| \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On a big scale:\n",
    "To compress sequences that are generally the same, we would recommend gzip. Assuming this ratio is same for many other various genomic sequences, we'd be compression to about 25% of the original. For protein sequences, we would recommend pbzip2 since it is faster than bzip2. This is about 50% of the original. Finally for the completely random sequences, arithmetic compression seems to be the best option. Although the compression ratio is pretty close to 1, it could get down to about 90% of the original file. Starting out with 1000 TB of data, 80% is 800 TB out of which we can compress down to 25 % of it which is 200 TB. The next 10% (100 TB) can be compressed down by 50% which means 50 TB. The last 100 TB is random and can (approximately, considering worst case) be compressed down to 90 TB. This means from the original 1000 TB we now have 340 TB. We saved 660 TB of space which is 66%. 66% * 500 = 33,000. The bonus is $33,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
